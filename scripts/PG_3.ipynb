{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7208095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48fc92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(\"/home/think/Desktop/all_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39e4845",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.drop(all_df.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e5886c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.102960</td>\n",
       "      <td>0.107116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.091243</td>\n",
       "      <td>0.105749</td>\n",
       "      <td>0.114304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.086763</td>\n",
       "      <td>0.108366</td>\n",
       "      <td>0.121566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.082225</td>\n",
       "      <td>0.110810</td>\n",
       "      <td>0.128902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>500</td>\n",
       "      <td>0.697298</td>\n",
       "      <td>-0.201389</td>\n",
       "      <td>0.617136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>500</td>\n",
       "      <td>0.696305</td>\n",
       "      <td>-0.202385</td>\n",
       "      <td>0.618926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>500</td>\n",
       "      <td>0.695297</td>\n",
       "      <td>-0.203362</td>\n",
       "      <td>0.620717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>500</td>\n",
       "      <td>0.694274</td>\n",
       "      <td>-0.204320</td>\n",
       "      <td>0.622507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>500</td>\n",
       "      <td>0.693237</td>\n",
       "      <td>-0.205257</td>\n",
       "      <td>0.624298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         x         y         z\n",
       "0          1  0.100000  0.100000  0.100000\n",
       "1          1  0.095657  0.102960  0.107116\n",
       "2          1  0.091243  0.105749  0.114304\n",
       "3          1  0.086763  0.108366  0.121566\n",
       "4          1  0.082225  0.110810  0.128902\n",
       "...      ...       ...       ...       ...\n",
       "4999995  500  0.697298 -0.201389  0.617136\n",
       "4999996  500  0.696305 -0.202385  0.618926\n",
       "4999997  500  0.695297 -0.203362  0.620717\n",
       "4999998  500  0.694274 -0.204320  0.622507\n",
       "4999999  500  0.693237 -0.205257  0.624298\n",
       "\n",
       "[5000000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0a814d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nolds\n",
    "\n",
    "def extract_chaos_features(series):\n",
    "    \"\"\"Extract chaos features from a 1D time series.\"\"\"\n",
    "    return {\n",
    "        'lyap': nolds.lyap_r(series),\n",
    "        'corr_dim': nolds.corr_dim(series, emb_dim=10),\n",
    "        'ap_entropy': nolds.sampen(series),\n",
    "    }\n",
    "\n",
    "def compute_features_by_id(df_all):\n",
    "    \"\"\"\n",
    "    Agrupa por 'id' y calcula las features para cada grupo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_all : pd.DataFrame\n",
    "        DataFrame con columnas ['id', 'x', 'y', 'z']\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con columnas ['id', 'lyap', 'corr_dim', 'ap_entropy']\n",
    "    \"\"\"\n",
    "\n",
    "    feature_rows = []\n",
    "\n",
    "    for id_value, group in df_all.groupby(\"id\"):\n",
    "        try:\n",
    "            x_series = group[\"y\"].values\n",
    "            features = extract_chaos_features(x_series)\n",
    "            features[\"id\"] = id_value\n",
    "            feature_rows.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating features for id {id_value}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(feature_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10cb1804",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = all_df.iloc[1:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83079069",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df_new = subset_df[[\"id\", \"y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e8cd302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.102960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.105749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.108366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.110810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.804275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.843197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.880443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.915961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.949707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         y\n",
       "1      1  0.102960\n",
       "2      1  0.105749\n",
       "3      1  0.108366\n",
       "4      1  0.110810\n",
       "5      1  0.113081\n",
       "...   ..       ...\n",
       "9995   1 -0.804275\n",
       "9996   1 -0.843197\n",
       "9997   1 -0.880443\n",
       "9998   1 -0.915961\n",
       "9999   1 -0.949707\n",
       "\n",
       "[9999 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16900fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       lyap  corr_dim  ap_entropy  id\n",
      "0  0.000575  1.359338    0.068571   1\n"
     ]
    }
   ],
   "source": [
    "features_df = compute_features_by_id(subset_df_new)\n",
    "features_df = features_df.sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a349511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyap</th>\n",
       "      <th>corr_dim</th>\n",
       "      <th>ap_entropy</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000575</td>\n",
       "      <td>1.359338</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lyap  corr_dim  ap_entropy  id\n",
       "0  0.000575  1.359338    0.068571   1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa8aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "\n",
    "def process_tsfresh_features(\n",
    "    all_df,\n",
    "    select_ids=None,\n",
    "    variables=None,\n",
    "    default_fc_parameters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts tsfresh features per id and per variable separately.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_df : pd.DataFrame\n",
    "        Must have columns ['id', 'x', 'y', 'z'], where multiple rows per id.\n",
    "    select_ids : list[int], optional\n",
    "        Which ids to process.\n",
    "    variables : list[str], optional\n",
    "        Which of ['x', 'y', 'z'] to process. None = all present.\n",
    "    default_fc_parameters : dict, optional\n",
    "        Feature calc params passed to tsfresh.extract_features()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One row per id, columns like x__feature1, y__feature1, etc.\n",
    "    \"\"\"\n",
    "    if select_ids is None:\n",
    "        select_ids = all_df['id'].unique().tolist()\n",
    "    if variables is None:\n",
    "        variables = [c for c in ['x', 'y', 'z'] if c in all_df.columns]\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for sid in select_ids:\n",
    "        ts = all_df[all_df['id'] == sid]\n",
    "        record = {'id': sid}\n",
    "        if ts.empty:\n",
    "            print(f\"⚠️ id {sid} not found in all_df — skipping\")\n",
    "            continue\n",
    "\n",
    "        for var in variables:\n",
    "            if var not in ts.columns:\n",
    "                print(f\"⚠️ column '{var}' not found — skipping {sid}\")\n",
    "                continue\n",
    "\n",
    "            # Shape: id, time index, value\n",
    "            temp_df = pd.DataFrame({\n",
    "                'id': sid,\n",
    "                'time': range(len(ts)),\n",
    "                'value': ts[var].values\n",
    "            })\n",
    "            # extract_features expects column_id, column_sort, column_value\n",
    "            features_df = extract_features(\n",
    "                temp_df,\n",
    "                column_id='id',\n",
    "                column_sort='time',\n",
    "                column_value='value',\n",
    "                default_fc_parameters=default_fc_parameters\n",
    "            )\n",
    "\n",
    "            # Prefix the feature columns with the variable name\n",
    "            features_df.columns = [f\"{var}__{c}\" for c in features_df.columns]\n",
    "\n",
    "            # Save features as a dict\n",
    "            record.update(features_df.iloc[0].to_dict())\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33915555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [01:12<00:00, 72.05s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.66s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.41s/it]\n"
     ]
    }
   ],
   "source": [
    "tsdf = process_tsfresh_features(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b39a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x__value__variance_larger_than_standard_deviation</th>\n",
       "      <th>x__value__has_duplicate_max</th>\n",
       "      <th>x__value__has_duplicate_min</th>\n",
       "      <th>x__value__has_duplicate</th>\n",
       "      <th>x__value__sum_values</th>\n",
       "      <th>x__value__abs_energy</th>\n",
       "      <th>x__value__mean_abs_change</th>\n",
       "      <th>x__value__mean_change</th>\n",
       "      <th>x__value__mean_second_derivative_central</th>\n",
       "      <th>...</th>\n",
       "      <th>z__value__fourier_entropy__bins_5</th>\n",
       "      <th>z__value__fourier_entropy__bins_10</th>\n",
       "      <th>z__value__fourier_entropy__bins_100</th>\n",
       "      <th>z__value__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>z__value__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>z__value__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>z__value__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>z__value__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>z__value__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>z__value__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-143.879924</td>\n",
       "      <td>2644.996813</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.707022</td>\n",
       "      <td>0.72883</td>\n",
       "      <td>0.750632</td>\n",
       "      <td>0.77243</td>\n",
       "      <td>0.794223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.881531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 2350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  x__value__variance_larger_than_standard_deviation  \\\n",
       "0   1                                                0.0   \n",
       "\n",
       "   x__value__has_duplicate_max  x__value__has_duplicate_min  \\\n",
       "0                          0.0                          0.0   \n",
       "\n",
       "   x__value__has_duplicate  x__value__sum_values  x__value__abs_energy  \\\n",
       "0                      0.0           -143.879924           2644.996813   \n",
       "\n",
       "   x__value__mean_abs_change  x__value__mean_change  \\\n",
       "0                   0.012985              -0.000113   \n",
       "\n",
       "   x__value__mean_second_derivative_central  ...  \\\n",
       "0                                  0.000002  ...   \n",
       "\n",
       "   z__value__fourier_entropy__bins_5  z__value__fourier_entropy__bins_10  \\\n",
       "0                           0.045395                            0.090729   \n",
       "\n",
       "   z__value__fourier_entropy__bins_100  \\\n",
       "0                             0.136002   \n",
       "\n",
       "   z__value__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                           0.707022   \n",
       "\n",
       "   z__value__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                            0.72883   \n",
       "\n",
       "   z__value__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                           0.750632   \n",
       "\n",
       "   z__value__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                            0.77243   \n",
       "\n",
       "   z__value__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                           0.794223   \n",
       "\n",
       "   z__value__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                NaN             \n",
       "\n",
       "   z__value__mean_n_absolute_max__number_of_maxima_7  \n",
       "0                                           1.881531  \n",
       "\n",
       "[1 rows x 2350 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37e70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "\n",
    "def process_tsfresh_features_long(\n",
    "    all_df,\n",
    "    select_ids=None,\n",
    "    variables=None,\n",
    "    default_fc_parameters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Extracts tsfresh features per id and per variable separately,\n",
    "    returning one row per (id, axis).\n",
    "    \"\"\"\n",
    "    if select_ids is None:\n",
    "        select_ids = all_df['id'].unique().tolist()\n",
    "    if variables is None:\n",
    "        variables = [c for c in ['x', 'y', 'z'] if c in all_df.columns]\n",
    "\n",
    "    records = []\n",
    "    for sid in select_ids:\n",
    "        ts = all_df[all_df['id'] == sid]\n",
    "        if ts.empty:\n",
    "            continue\n",
    "\n",
    "        for var in variables:\n",
    "            temp_df = pd.DataFrame(\n",
    "                {'id': sid, 'time': range(len(ts)), 'value': ts[var].values}\n",
    "            )\n",
    "            features_df = extract_features(\n",
    "                temp_df,\n",
    "                column_id='id',\n",
    "                column_sort='time',\n",
    "                column_value='value',\n",
    "                default_fc_parameters=default_fc_parameters\n",
    "            )\n",
    "            features_df['id'] = sid\n",
    "            features_df['axis'] = var\n",
    "            records.append(features_df)\n",
    "\n",
    "    # Concatenate all results vertically\n",
    "    result_df = pd.concat(records, ignore_index=True)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3b55bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.38s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:09<00:00, 69.74s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.67s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.47s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.50s/it]\n",
      "Feature Extraction: 100%|██████████| 1/1 [01:10<00:00, 70.07s/it]\n"
     ]
    }
   ],
   "source": [
    "tsdf = process_tsfresh_features_long(subset_df,\n",
    "                                     variables=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c5304cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value__variance_larger_than_standard_deviation</th>\n",
       "      <th>value__has_duplicate_max</th>\n",
       "      <th>value__has_duplicate_min</th>\n",
       "      <th>value__has_duplicate</th>\n",
       "      <th>value__sum_values</th>\n",
       "      <th>value__abs_energy</th>\n",
       "      <th>value__mean_abs_change</th>\n",
       "      <th>value__mean_change</th>\n",
       "      <th>value__mean_second_derivative_central</th>\n",
       "      <th>value__median</th>\n",
       "      <th>...</th>\n",
       "      <th>value__fourier_entropy__bins_100</th>\n",
       "      <th>value__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>value__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>value__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>value__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "      <th>id</th>\n",
       "      <th>axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-143.879924</td>\n",
       "      <td>2644.996813</td>\n",
       "      <td>0.012985</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>2.224768e-06</td>\n",
       "      <td>-0.001344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.764904</td>\n",
       "      <td>0.836534</td>\n",
       "      <td>0.909230</td>\n",
       "      <td>0.981796</td>\n",
       "      <td>1.054230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.519426</td>\n",
       "      <td>1</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.753485</td>\n",
       "      <td>2612.465651</td>\n",
       "      <td>0.013024</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-1.827286e-06</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>0.836566</td>\n",
       "      <td>0.908088</td>\n",
       "      <td>0.980347</td>\n",
       "      <td>1.053223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.530853</td>\n",
       "      <td>1</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-143.523062</td>\n",
       "      <td>2667.869550</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>2.554791e-06</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.764886</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>0.907986</td>\n",
       "      <td>0.980212</td>\n",
       "      <td>1.052306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.513167</td>\n",
       "      <td>2</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.093597</td>\n",
       "      <td>2650.657201</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-4.126253e-07</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.764843</td>\n",
       "      <td>0.836430</td>\n",
       "      <td>0.908339</td>\n",
       "      <td>0.981302</td>\n",
       "      <td>1.054133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.547837</td>\n",
       "      <td>2</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-112.347772</td>\n",
       "      <td>2694.698148</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.057021e-06</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.764925</td>\n",
       "      <td>0.837026</td>\n",
       "      <td>0.908998</td>\n",
       "      <td>0.980840</td>\n",
       "      <td>1.054291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.498174</td>\n",
       "      <td>3</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.732843</td>\n",
       "      <td>2704.570660</td>\n",
       "      <td>0.013243</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>7.166387e-07</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.765412</td>\n",
       "      <td>0.837570</td>\n",
       "      <td>0.910470</td>\n",
       "      <td>0.984422</td>\n",
       "      <td>1.059106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.558760</td>\n",
       "      <td>3</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   value__variance_larger_than_standard_deviation  value__has_duplicate_max  \\\n",
       "0                                             0.0                       0.0   \n",
       "1                                             0.0                       0.0   \n",
       "2                                             0.0                       0.0   \n",
       "3                                             0.0                       0.0   \n",
       "4                                             0.0                       0.0   \n",
       "5                                             0.0                       0.0   \n",
       "\n",
       "   value__has_duplicate_min  value__has_duplicate  value__sum_values  \\\n",
       "0                       0.0                   0.0        -143.879924   \n",
       "1                       0.0                   0.0         134.753485   \n",
       "2                       0.0                   0.0        -143.523062   \n",
       "3                       0.0                   0.0         128.093597   \n",
       "4                       0.0                   0.0        -112.347772   \n",
       "5                       0.0                   0.0         127.732843   \n",
       "\n",
       "   value__abs_energy  value__mean_abs_change  value__mean_change  \\\n",
       "0        2644.996813                0.012985           -0.000113   \n",
       "1        2612.465651                0.013024           -0.000105   \n",
       "2        2667.869550                0.013117           -0.000048   \n",
       "3        2650.657201                0.013117           -0.000128   \n",
       "4        2694.698148                0.013282            0.000011   \n",
       "5        2704.570660                0.013243           -0.000114   \n",
       "\n",
       "   value__mean_second_derivative_central  value__median  ...  \\\n",
       "0                           2.224768e-06      -0.001344  ...   \n",
       "1                          -1.827286e-06       0.001307  ...   \n",
       "2                           2.554791e-06      -0.001785  ...   \n",
       "3                          -4.126253e-07       0.001151  ...   \n",
       "4                           2.057021e-06      -0.001988  ...   \n",
       "5                           7.166387e-07       0.000560  ...   \n",
       "\n",
       "   value__fourier_entropy__bins_100  \\\n",
       "0                          0.181214   \n",
       "1                          0.181214   \n",
       "2                          0.181214   \n",
       "3                          0.181214   \n",
       "4                          0.181214   \n",
       "5                          0.181214   \n",
       "\n",
       "   value__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                        0.764904   \n",
       "1                                        0.764915   \n",
       "2                                        0.764886   \n",
       "3                                        0.764843   \n",
       "4                                        0.764925   \n",
       "5                                        0.765412   \n",
       "\n",
       "   value__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                        0.836534   \n",
       "1                                        0.836566   \n",
       "2                                        0.836500   \n",
       "3                                        0.836430   \n",
       "4                                        0.837026   \n",
       "5                                        0.837570   \n",
       "\n",
       "   value__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                        0.909230   \n",
       "1                                        0.908088   \n",
       "2                                        0.907986   \n",
       "3                                        0.908339   \n",
       "4                                        0.908998   \n",
       "5                                        0.910470   \n",
       "\n",
       "   value__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                        0.981796   \n",
       "1                                        0.980347   \n",
       "2                                        0.980212   \n",
       "3                                        0.981302   \n",
       "4                                        0.980840   \n",
       "5                                        0.984422   \n",
       "\n",
       "   value__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                        1.054230   \n",
       "1                                        1.053223   \n",
       "2                                        1.052306   \n",
       "3                                        1.054133   \n",
       "4                                        1.054291   \n",
       "5                                        1.059106   \n",
       "\n",
       "   value__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                NaN          \n",
       "1                                                NaN          \n",
       "2                                                NaN          \n",
       "3                                                NaN          \n",
       "4                                                NaN          \n",
       "5                                                NaN          \n",
       "\n",
       "   value__mean_n_absolute_max__number_of_maxima_7  id  axis  \n",
       "0                                        1.519426   1     x  \n",
       "1                                        1.530853   1     y  \n",
       "2                                        1.513167   2     x  \n",
       "3                                        1.547837   2     y  \n",
       "4                                        1.498174   3     x  \n",
       "5                                        1.558760   3     y  \n",
       "\n",
       "[6 rows x 785 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 1/1 [01:08<00:00, 68.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features\n",
    "weee = extract_features(subset_df_new, column_id='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a73a7aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x__variance_larger_than_standard_deviation</th>\n",
       "      <th>x__has_duplicate_max</th>\n",
       "      <th>x__has_duplicate_min</th>\n",
       "      <th>x__has_duplicate</th>\n",
       "      <th>x__sum_values</th>\n",
       "      <th>x__abs_energy</th>\n",
       "      <th>x__mean_abs_change</th>\n",
       "      <th>x__mean_change</th>\n",
       "      <th>x__mean_second_derivative_central</th>\n",
       "      <th>x__median</th>\n",
       "      <th>...</th>\n",
       "      <th>x__fourier_entropy__bins_5</th>\n",
       "      <th>x__fourier_entropy__bins_10</th>\n",
       "      <th>x__fourier_entropy__bins_100</th>\n",
       "      <th>x__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>x__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>x__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>x__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>x__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>x__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>x__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-143.779924</td>\n",
       "      <td>2645.006813</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>0.136002</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>0.764898</td>\n",
       "      <td>0.836522</td>\n",
       "      <td>0.909212</td>\n",
       "      <td>0.981772</td>\n",
       "      <td>1.0542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.519426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x__variance_larger_than_standard_deviation  x__has_duplicate_max  \\\n",
       "1                                         0.0                   0.0   \n",
       "\n",
       "   x__has_duplicate_min  x__has_duplicate  x__sum_values  x__abs_energy  \\\n",
       "1                   0.0               0.0    -143.779924    2645.006813   \n",
       "\n",
       "   x__mean_abs_change  x__mean_change  x__mean_second_derivative_central  \\\n",
       "1            0.012984       -0.000114                           0.000002   \n",
       "\n",
       "   x__median  ...  x__fourier_entropy__bins_5  x__fourier_entropy__bins_10  \\\n",
       "1  -0.001322  ...                    0.079983                     0.136002   \n",
       "\n",
       "   x__fourier_entropy__bins_100  x__permutation_entropy__dimension_3__tau_1  \\\n",
       "1                      0.181214                                    0.764898   \n",
       "\n",
       "   x__permutation_entropy__dimension_4__tau_1  \\\n",
       "1                                    0.836522   \n",
       "\n",
       "   x__permutation_entropy__dimension_5__tau_1  \\\n",
       "1                                    0.909212   \n",
       "\n",
       "   x__permutation_entropy__dimension_6__tau_1  \\\n",
       "1                                    0.981772   \n",
       "\n",
       "   x__permutation_entropy__dimension_7__tau_1  \\\n",
       "1                                      1.0542   \n",
       "\n",
       "   x__query_similarity_count__query_None__threshold_0.0  \\\n",
       "1                                                NaN      \n",
       "\n",
       "   x__mean_n_absolute_max__number_of_maxima_7  \n",
       "1                                    1.519426  \n",
       "\n",
       "[1 rows x 783 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b646ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
